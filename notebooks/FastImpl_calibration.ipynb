{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the sequential segmentation algorithm with simulated data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import sys\n",
    "sys.path.append('/home/paulo/github')\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from bayeseg.SeqSeg import SeqSeg\n",
    "\n",
    "savefolder = '/home/paulo/github/bayeseg/Output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing time for various time resolutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size = 10000, tres = 1, t =  0.013075113296508789\n",
      "Size = 10000, tres = 10, t =  0.01116800308227539\n",
      "Size = 10000, tres = 100, t =  0.009931087493896484\n",
      "Size = 10000, tres = 1000, t =  0.011090517044067383\n",
      "Size = 100000, tres = 1, t =  0.0749046802520752\n",
      "Size = 100000, tres = 10, t =  0.007799386978149414\n",
      "Size = 100000, tres = 100, t =  0.0027260780334472656\n",
      "Size = 100000, tres = 1000, t =  0.0019636154174804688\n",
      "Size = 1000000, tres = 1, t =  0.45624852180480957\n",
      "Size = 1000000, tres = 10, t =  0.05502486228942871\n",
      "Size = 1000000, tres = 100, t =  0.014348030090332031\n",
      "Size = 1000000, tres = 1000, t =  0.008195877075195312\n",
      "10000 & 1 & 0.01308 \\\\\n",
      "10000 & 10 & 0.01117 \\\\\n",
      "10000 & 100 & 0.009931 \\\\\n",
      "10000 & 1000 & 0.01109 \\\\\n",
      "100000 & 1 & 0.0749 \\\\\n",
      "100000 & 10 & 0.007799 \\\\\n",
      "100000 & 100 & 0.002726 \\\\\n",
      "100000 & 1000 & 0.001964 \\\\\n",
      "1000000 & 1 & 0.4562 \\\\\n",
      "1000000 & 10 & 0.05502 \\\\\n",
      "1000000 & 100 & 0.01435 \\\\\n",
      "1000000 & 1000 & 0.008196 \\\\\n"
     ]
    }
   ],
   "source": [
    "ss = SeqSeg()\n",
    "\n",
    "\n",
    "sizes = [10000, 100000, 1000000]\n",
    "tres = [1, 10, 100, 1000]\n",
    "\n",
    "ss.initialize(1, 0.1, 100, 200, 1)\n",
    "result = []\n",
    "for size in sizes:\n",
    "    signal = np.random.normal(0, 1, [size, 1])\n",
    "    ss.feed_data(signal)\n",
    "    for res in tres:\n",
    "        t, tdur = ss.segments(minlen = 1000000, res = res, verbose = False)\n",
    "        print(\"Size = \" + str(size) + \", tres = \" + str(res) + \", t = \", str(tdur))\n",
    "        result.append([size, res, tdur])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing $\\alpha$ and $\\beta$ with many segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "npoints = 1000000\n",
    "cuts = [10000, 110000, 200000, 500000, 750000, 1000000]\n",
    "deltalist = [1, 1.1, 1.5]\n",
    "stdnoise = 1\n",
    "\n",
    "mciter = 10000\n",
    "mcburn = 10000\n",
    "alphalist = [0.1, 0.5, 0.9, 0.99]\n",
    "betalist = [1, 1e-1, 1e-2, 1e-3, 2e-3, 5e-3, 1e-4, 5e-4, 1e-5, 1e-6]\n",
    "\n",
    "nruns = 30\n",
    "\n",
    "ss = SeqSeg()\n",
    "res = []\n",
    "for delta in deltalist:\n",
    "    # Simulates signal\n",
    "    signal = np.random.normal(0, 1, [npoints, 1])\n",
    "    for i in range(len(cuts)):\n",
    "        if (i+1)%2:\n",
    "            signal[cuts[i]:cuts[i+1]] = signal[cuts[i]:cuts[i+1]]*(np.sqrt(delta))\n",
    "    ss.feed_data(signal)\n",
    "    for beta in betalist:\n",
    "        for alpha in alphalist:\n",
    "            ss.initialize(beta, alpha, mciter, mcburn, nchains = 1)\n",
    "            nsegmean = 0\n",
    "            minseg = 500000\n",
    "            maxseg = 0\n",
    "            tmean = 0\n",
    "            for i in range(nruns):\n",
    "                t, tdur = ss.segments(minlen = 5000, res = 100, verbose = False)\n",
    "                nsegmean = nsegmean + (len(t)+1)/nruns\n",
    "                tmean = tmean + tdur / nruns\n",
    "                if len(t) + 1 < minseg:\n",
    "                    minseg = len(t) + 1\n",
    "                if len(t) + 1 > maxseg:\n",
    "                    maxseg = len(t) + 1\n",
    "            \n",
    "            print(\"Delta = \" + str(delta) + \", alpha = \" + str(alpha) + \", beta = \" + str(beta) + \", \" + str(nsegmean) + \" segments on average in \" + \"{:.2}\".format(tmean) + \" seconds.\")\n",
    "                \n",
    "            res.append([delta, beta, alpha, nsegmean, minseg, maxseg, tdur])\n",
    "            \n",
    "\n",
    "df = pd.DataFrame(res, columns = ['delta', 'beta', 'alpha', 'nsegmean', 'minseg', 'maxseg', 'tmean'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration for a grid of $\\beta$ and $\\alpha$ with varying delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signal characteristics\n",
    "npoints = 1000000\n",
    "cuts = [10000, 110000, 200000, 500000, 750000, 1000000]\n",
    "delta = [1.1, 1, 1.5, 1, 1.2]\n",
    "stdnoise = 1\n",
    "\n",
    "mciter = 10000\n",
    "mcburn = 10000\n",
    "\n",
    "# Alpha grid\n",
    "alphamin = 0.1\n",
    "alphamax = 0.1\n",
    "nstep = 0\n",
    "adelta = (alphamax - alphamin) / max(1, nstep)\n",
    "alphalist = [alphamin + d*adelta for d in range(nstep+1)]\n",
    "\n",
    "# Beta grid\n",
    "betamin = 1e-3\n",
    "betamax = 1e-1\n",
    "nstep = 100\n",
    "bdelta = (betamax - betamin) / max(1, nstep)\n",
    "betalist = [betamin + d*bdelta for d in range(nstep+1)]\n",
    "\n",
    "# To use union of two separate grids \n",
    "#betamin = 1e-3\n",
    "#betamax = 1e-1\n",
    "#nstep = 100\n",
    "#bdelta = (betamax - betamin) / max(1, nstep)\n",
    "#betalist = betalist + [betamin + d*bdelta for d in range(nstep+1)]\n",
    "\n",
    "# Number of segmentations to run for each combination of parameters\n",
    "nruns = 1\n",
    "\n",
    "ss = SeqSeg()\n",
    "res = []\n",
    "\n",
    "# Simulates signal\n",
    "signal = np.random.normal(0, stdnoise, [npoints, 1])\n",
    "for i in range(len(cuts)-1):\n",
    "    signal[cuts[i]:cuts[i+1]] = signal[cuts[i]:cuts[i+1]]*(np.sqrt(delta[i]))\n",
    "\n",
    "\n",
    "ss.feed_data(signal)        \n",
    "result = []\n",
    "tresult = []\n",
    "cont = 1\n",
    "ntotal = len(betalist)*len(alphalist)\n",
    "for alpha in alphalist:\n",
    "    for beta in betalist:\n",
    "        ss.initialize(beta, alpha, mciter, mcburn, nchains = 1)\n",
    "        t, tdur = ss.segments(minlen = 5000, res = 1, verbose = False)\n",
    "        result.append([alpha, beta, len(t)+1])\n",
    "        #t.sort()\n",
    "        tresult.append(t)\n",
    "\n",
    "        print('({:.2%})'.format(cont/ntotal) + ' Alpha = {:.3}'.format(alpha) + ', Beta = {:.5}'.format(beta) + \", \" + str(len(t)+1) + \" segments\")\n",
    "        cont = cont + 1         \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
